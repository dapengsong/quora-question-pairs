{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grapefroot/ds3/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers.transformers import AdamW, WarmupLinearSchedule\n",
    "from transformers.transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "from transformers import transformers\n",
    "from transformers.transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n",
    "\n",
    "from layers import VectorAttention, NNAttention, Seq2SeqAttention\n",
    "from utils import QuoraSentences, collate_fn, collate_fn_test, evaluate\n",
    "from models import SentenceClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_weights = 'roberta-base'\n",
    "model_weights = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained(model_weights)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_weights, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = RobertaModel.from_pretrained(model_weights, output_hidden_states=True, output_attentions=True).cuda()\n",
    "model=BertForSequenceClassification.from_pretrained(model_weights, output_hidden_states=True).cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grapefroot/ds3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='id')\n",
    "train.dropna(axis=0, inplace=True)\n",
    "test = pd.read_csv('data/test.csv', index_col='test_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_str(string, *args, **kwargs):\n",
    "    return tokenizer.encode(string, *args, **kwargs)\n",
    "\n",
    "class QuoraSentences(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tk, train=True):\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        if self.train:\n",
    "            self.df.dropna(inplace=True, axis=0)\n",
    "        self.enc = tk.encode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q_1, q_2 = self.df.iloc[idx][['question1', 'question2']]\n",
    "        enc_1 = self.enc(q_1.lower(), add_special_tokens=True, return_tensors='pt').squeeze()        \n",
    "        enc_2 = self.enc(q_2.lower(), add_special_tokens=True, return_tensors='pt').squeeze()\n",
    "        if self.train:\n",
    "            is_dup = self.df.iloc[idx]['is_duplicate']\n",
    "            return enc_1, enc_2, is_dup\n",
    "        return enc_1, enc_2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    #calculate max length\n",
    "    max1 = max([item[0].size() for item in batch])\n",
    "    max2 = max([item[1].size() for item in batch])\n",
    "    \n",
    "    q1_batch, q1_mask, q2_batch, q2_mask = [], [], [], []\n",
    "    y = []\n",
    "    \n",
    "    for enc_1, enc_2, is_dup in batch:\n",
    "        padded_1 = enc_1.new_zeros(max1)\n",
    "        padded_1[:len(enc_1)] = enc_1\n",
    "        att_mask_1 = enc_1.new_zeros(max1, dtype=torch.float)\n",
    "        att_mask_1[:len(enc_1)] = 1\n",
    "        q1_batch.append(padded_1)\n",
    "        q1_mask.append(att_mask_1)\n",
    "        \n",
    "        padded_2 = enc_2.new_zeros(max2)\n",
    "        padded_2[:len(enc_2)] = enc_2\n",
    "        att_mask_2 = enc_2.new_zeros(max2, dtype=torch.float)\n",
    "        att_mask_2[:len(enc_2)] = 1\n",
    "        q2_batch.append(padded_2)\n",
    "        q2_mask.append(att_mask_2)\n",
    "        \n",
    "        y.append(is_dup)\n",
    "        \n",
    "    return torch.stack(q1_batch), torch.stack(q1_mask), torch.stack(q2_batch), torch.stack(q2_mask), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_test(batch):\n",
    "    #calculate max length\n",
    "    max1 = max([item[0].size() for item in batch])\n",
    "    max2 = max([item[1].size() for item in batch])\n",
    "    \n",
    "    q1_batch, q1_mask, q2_batch, q2_mask = [], [], [], []\n",
    "    \n",
    "    for enc_1, enc_2 in batch:\n",
    "        padded_1 = enc_1.new_zeros(max1)\n",
    "        padded_1[:len(enc_1)] = enc_1\n",
    "        att_mask_1 = enc_1.new_zeros(max1, dtype=torch.float)\n",
    "        att_mask_1[:len(enc_1)] = 1\n",
    "        q1_batch.append(padded_1)\n",
    "        q1_mask.append(att_mask_1)\n",
    "        \n",
    "        padded_2 = enc_2.new_zeros(max2)\n",
    "        padded_2[:len(enc_2)] = enc_2\n",
    "        att_mask_2 = enc_2.new_zeros(max2, dtype=torch.float)\n",
    "        att_mask_2[:len(enc_2)] = 1\n",
    "        q2_batch.append(padded_2)\n",
    "        q2_mask.append(att_mask_2)\n",
    "    return torch.stack(q1_batch), torch.stack(q1_mask), torch.stack(q2_batch), torch.stack(q2_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClf(torch.nn.Module):\n",
    "    def __init__(self, emb_model):\n",
    "        super(SentenceClf, self).__init__()\n",
    "        self.emb_model = emb_model\n",
    "        self.emb_size = 768\n",
    "        self.clf = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.emb_size * 2, 512),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.LayerNorm(512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.LayerNorm(512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.LayerNorm(256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(256, 2)\n",
    "        ).cuda()\n",
    "        self.attn_block = attn_block.cuda()\n",
    "        \n",
    "    \n",
    "    def forward(self, enc_1, mask_1, enc_2, mask_2):\n",
    "        #average, concatenate, process with mlp\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            hidden_1 = self.emb_model(enc_1, attention_mask = mask_1)[2][-2]\n",
    "            hidden_2 = self.emb_model(enc_2, attention_mask = mask_2)[2][-2]\n",
    "\n",
    "            hidden_1_count = mask_1.sum(axis=1, keepdims=True)\n",
    "            hidden_2_count = mask_2.sum(axis=1, keepdims=True)\n",
    "        \n",
    "            first = (hidden_1 * mask_1.unsqueeze(2)).sum(axis=1) / hidden_1_count\n",
    "            second = (hidden_2 * mask_2.unsqueeze(2)).sum(axis=1) / hidden_2_count\n",
    "        \n",
    "#         first, second = self.attn_block(hidden_1, mask_1, hidden_2, mask_2)\n",
    "    \n",
    "        #input: batch_size x word_size x embed_dim\n",
    "        mlp_input = torch.cat(\n",
    "            (first, second),\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        return self.clf(mlp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = VectorAttention(768)\n",
    "\n",
    "sc = SentenceClf(model, attn)\n",
    "#sc.clf.load_state_dict(torch.load('models/clf_head_weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grapefroot/ds3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "ds_train = QuoraSentences(train[:-5000], tokenizer)\n",
    "ds_val = QuoraSentences(train.iloc[-5000:], tokenizer)\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=100, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(ds_val, batch_size=50, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, Adadelta, SGD\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(chain(sc.clf.parameters(), sc.attn_block.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.transformers import WarmupCosineSchedule\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(optim, milestones=[20, 40], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0 if iter_num is None else iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [3:12:42<61:00:41, 2312.02s/it]/home/grapefroot/ds3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      " 10%|█         | 10/100 [6:25:35<57:51:27, 2314.31s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-825793c62b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mlv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m#writer.add_scalar('data/train_logloss', lv.item(), iter_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0macc_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iter_num in tqdm(range(start_epoch, N_EPOCHS), position=0):\n",
    "    sc.clf.eval()\n",
    "    val_list = []\n",
    "    for q1, m1, q2, m2, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outs = sc(q1.cuda(), m1.cuda(), q2.cuda(), m2.cuda())\n",
    "            val_loss = loss(outs, target.cuda()).mean().item()\n",
    "            val_list.append(val_loss)\n",
    "    writer.add_scalar('data/val_logloss', sum(val_list) / len(val_list), iter_num)\n",
    "    \n",
    "    if iter_num > 0 and iter_num % 5 == 0:\n",
    "        torch.save(\n",
    "        {\n",
    "            'epoch': iter_num,\n",
    "            'model_state_dict': sc.clf.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'loss': loss,\n",
    "            'val_metric': sum(val_list) / len(val_list)\n",
    "        }, 'models/checkpoint_iter_{}_{}'.format(iter_num, datetime.now()))\n",
    "    \n",
    "    \n",
    "    sc.clf.train()\n",
    "    acc_loss = 0\n",
    "    n_batches = 0\n",
    "    for q1, m1, q2, m2, target in train_loader:\n",
    "        optim.zero_grad()\n",
    "        outs = sc(q1.cuda(), m1.cuda(), q2.cuda(), m2.cuda())\n",
    "        lv = loss(outs, target.cuda()).mean()\n",
    "        #writer.add_scalar('data/train_logloss', lv.item(), iter_num)\n",
    "        acc_loss+=lv.item()\n",
    "        n_batches+=1\n",
    "        lv.backward()\n",
    "        optim.step()\n",
    "    writer.add_scalar('data/train_logloss', acc_loss / n_batches, iter_num)\n",
    "    \n",
    "    scheduler.step()\n",
    "            \n",
    "writer.export_scalars_to_json('./scalars.json')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = []\n",
    "sc.eval()\n",
    "for q1, m1, q2, m2, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outs = sc(q1.cuda(), m1.cuda(), q2.cuda(), m2.cuda())\n",
    "            val_loss = loss(outs, target.cuda()).mean().item()\n",
    "            val_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sc.clf.state_dict(), './models/clf_head_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "sns.distplot(lens, ax=ax1)\n",
    "sns.distplot(lens2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23458/23458 [2:53:05<00:00,  2.26it/s]  \n"
     ]
    }
   ],
   "source": [
    "test_ds = QuoraSentences(test.dropna(), tokenizer, train=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=100, collate_fn=collate_fn_test, num_workers=3)\n",
    "\n",
    "ans = []\n",
    "def prepare_submission():\n",
    "    test_ds = QuoraSentences(test.dropna(), tokenizer, train=False)\n",
    "    test_dl = DataLoader(test_ds, batch_size=100, collate_fn=collate_fn_test, num_workers=3)\n",
    "    \n",
    "    sc.clf.eval()\n",
    "    for q1, m1, q2, m2 in tqdm(test_dl, position=0):\n",
    "        with torch.no_grad():\n",
    "            ans.append(sc(q1.cuda(), m1.cuda(), q2.cuda(), m2.cuda()).softmax(dim=1)[:, 1].cpu())\n",
    "    test['is_duplicate'] = 0\n",
    "    res_cpu = torch.cat(ans)\n",
    "    test.loc[test.dropna().index, 'is_duplicate'] = res_cpu.tolist()\n",
    "prepare_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['test_id', 'is_duplicate']].to_csv('sub_1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.192015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.326681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.215123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.447753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.878280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.987539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.580995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.058586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.042836\n",
       "1        1      0.192015\n",
       "2        2      0.326681\n",
       "3        3      0.136623\n",
       "4        4      0.215123\n",
       "5        5      0.447753\n",
       "6        6      0.878280\n",
       "7        7      0.987539\n",
       "8        8      0.580995\n",
       "9        9      0.058586"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sub_1.csv', nrows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_ds(df, save=None, train=True, tokenizer):\n",
    "    def process(str_1, str_2):\n",
    "        max_len=128\n",
    "        inputs = tokenizer.encode_plus(str_1, str_2, max_length=max_len, add_special_tokens=True)\n",
    "        pad_token_id = tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
    "        pad_token_segment_id = 0\n",
    "        input_ids = inputs['input_ids']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        pad_len = max_len - len(input_ids)\n",
    "        attn_mask = [1] * len(input_ids)\n",
    "        input_ids += [pad_token_id] * pad_len\n",
    "        attn_mask += [0] * pad_len\n",
    "        token_type_ids += [pad_token_segment_id] * pad_len\n",
    "        return input_ids, attn_mask, token_type_ids\n",
    "\n",
    "    id_list = []\n",
    "    qid1_list = []\n",
    "    qid2_list = []\n",
    "    input_id_list = []\n",
    "    attn_mask_list = []\n",
    "    token_type_ids_list = []\n",
    "    \n",
    "    if train:\n",
    "        is_duplicate_list = []\n",
    "\n",
    "        for id_, (qid1, qid2, question1, question2, is_dup) in tqdm(df.iterrows(), desc='Progress', position=0):\n",
    "            input_ids, attn_mask, token_type_ids = process(question1, question2)\n",
    "            id_list.append(id_)\n",
    "            qid1_list.append(qid1)\n",
    "            qid2_list.append(qid2)\n",
    "            input_id_list.append(input_ids)\n",
    "            attn_mask_list.append(attn_mask)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "            is_duplicate_list.append(is_dup)\n",
    "\n",
    "        ds = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(id_list),\n",
    "            torch.tensor(qid1_list),\n",
    "            torch.tensor(qid2_list),\n",
    "            torch.tensor(input_id_list),\n",
    "            torch.tensor(attn_mask_list),\n",
    "            torch.tensor(token_type_ids_list),\n",
    "            torch.tensor(is_duplicate_list),\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        for id_, (question1, question2) in tqdm(df.iterrows(), desc='Progress', position=0):\n",
    "            input_ids, attn_mask, token_type_ids = process(question1, question2)\n",
    "            id_list.append(id_)\n",
    "            input_id_list.append(input_ids)\n",
    "            attn_mask_list.append(attn_mask)\n",
    "            token_type_ids_list.append(token_type_ids)\n",
    "\n",
    "        ds = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(id_list),\n",
    "            torch.tensor(input_id_list),\n",
    "            torch.tensor(attn_mask_list),\n",
    "            torch.tensor(token_type_ids_list),\n",
    "        )\n",
    "    \n",
    "    if save is not None:\n",
    "        torch.save(ds, save)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-98cfedf45d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcache_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/train_ds_CASED_cached'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "cache_ds(train, './data/train_ds_CASED_cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_data = torch.load('./data/train_ds_CASED_cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(train_tensor_data, [len(train_tensor_data) - 10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.368995173566463"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nums_train) / len(nums_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3773"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nums) / len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(train_ds, batch_size=32, sampler=train_sampler)\n",
    "dl_val = DataLoader(val_ds, batch_size=8, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "t_total = n_epochs * len(dl_train)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=0, t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl_val):\n",
    "    loss = 0\n",
    "    steps = 0\n",
    "    preds = None\n",
    "    labels = None\n",
    "    for batch in dl_val:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tup = tuple(item.cuda() for item in batch[3:])\n",
    "            model_input = dict(zip(['input_ids', 'attention_mask', 'token_type_ids', 'labels'], tup))\n",
    "            logloss, logits = model(**model_input)[:2]\n",
    "            loss += logloss.mean().item()\n",
    "        steps+=1\n",
    "        \n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            labels = model_input['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            labels = np.append(labels, model_input['labels'].detach().cpu().numpy(), axis=0)\n",
    "    \n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    keys = ['logloss', 'accuracy', 'f1']\n",
    "    ll = logloss / steps\n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "    f1 = f1_score(labels, y_pred)\n",
    "    return zip(keys, (ll, accuracy, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_grad_norm = 1\n",
    "global_step = 0\n",
    "acc_loss = 0.0\n",
    "logging_loss = acc_loss\n",
    "model.zero_grad()\n",
    "log_step = 500\n",
    "max_steps = 15000\n",
    "\n",
    "epoch_range = trange(n_epochs, desc='Epoch', position=0, leave=True)\n",
    "\n",
    "for epoch_num in epoch_range:\n",
    "    epoch_iter = tqdm(dl_train, desc='Inside epoch {}'.format(epoch_num), position=1, leave=True)\n",
    "    for step, batch in enumerate(epoch_iter):\n",
    "        model.train()\n",
    "        \n",
    "        tup = tuple(item.cuda() for item in batch[3:])\n",
    "        model_input = dict(zip(['input_ids', 'attention_mask', 'token_type_ids', 'labels'], tup))\n",
    "        logloss, logits = model(**model_input)[:2]\n",
    "        \n",
    "        logloss.backward()\n",
    "        acc_loss += logloss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step % log_step == 0:\n",
    "            eval_res = evaluate(model)\n",
    "            for key, value in eval_res:\n",
    "                writer.add_scalar('eval_{}'.format(key), value, global_step=global_step)\n",
    "            writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "            writer.add_scalar('loss', (acc_loss - logging_loss) / log_step, global_step)\n",
    "            logging_loss = acc_loss\n",
    "    \n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch_num,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            #'loss': loss,\n",
    "            'val_metric': list(evaluate(model))\n",
    "        }, 'models/checkpoint_iter_{}_{}'.format(global_step, datetime.now()))\n",
    "    \n",
    "    if global_step >= max_steps:\n",
    "        break\n",
    "\n",
    "        \n",
    "        \n",
    "writer.export_scalars_to_json('./scalars_{}.json'.format(datetime.now()))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/checkpoint_iter_15000_2019-11-04 14:43:10.972407')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logloss', tensor(2.8814e-05, device='cuda:0')),\n",
       " ('accuracy', 0.9354),\n",
       " ('f1', 0.9105263157894737)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#     {\n",
    "#         'epoch': global_step,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'scheduler': scheduler.state_dict(),\n",
    "#         #'loss': loss,\n",
    "#         'val_metric': list(evaluate(model))\n",
    "#     }, 'models/checkpoint_iter_{}_{}'.format(global_step, datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cached_test_ds = cache_ds(test.dropna(), save='./data/test_ds_CASED_cached', train=False)\n",
    "test_ds = torch.load('./data/test_ds_CASED_cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.utils.data.WeightedRandomSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_subset = torch.utils.data.Subset(test_ds, torch.arange(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = torch.utils.data.SequentialSampler(test_ds_subset)\n",
    "dl_test = DataLoader(test_ds, batch_size=100, sampler=test_sampler)\n",
    "\n",
    "def process_test(model, dl_test):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dl_test, desc='Test Progress', position=0):\n",
    "        with torch.no_grad():\n",
    "            tup = tuple(item.cuda() for item in batch[1:])\n",
    "            model_input = dict(zip(['input_ids', 'attention_mask', 'token_type_ids'], tup))\n",
    "            logits = model(**model_input)[0]\n",
    "            \n",
    "        if preds is None:\n",
    "            preds = [logits.detach().cpu().softmax(axis=1).numpy()[:, 1]]\n",
    "        else:\n",
    "            preds.append(logits.detach().cpu().softmax(axis=1).numpy()[:, 1])\n",
    "      #  print(len(preds))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa976301e83344da800dbfcf16b98625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test Progress', style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = process_test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.concatenate(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00547964, 0.25859526, 0.00457108, ..., 0.00125954, 0.9906185 ,\n",
       "       0.11264461], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grapefroot/ds3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "cool_sub= pd.read_csv('./sub11.csv', index_col='test_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.135937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>0.002003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>0.013929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>0.681846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         is_duplicate\n",
       "test_id              \n",
       "0            0.004199\n",
       "1            0.135937\n",
       "2            0.029179\n",
       "3            0.011838\n",
       "4            0.025330\n",
       "...               ...\n",
       "2345791      0.000462\n",
       "2345792      0.002003\n",
       "2345793      0.000318\n",
       "2345794      0.013929\n",
       "2345795      0.681846\n",
       "\n",
       "[2345796 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cool_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_answers = np.load('./test_answers.npy')\n",
    "prev_answers[:10000] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278240"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prev_answers > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('./test_answers.npy', answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_duplicate'] = 0\n",
    "test.loc[test.dropna().index, 'is_duplicate'] = prev_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['is_duplicate']].to_csv('sub_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grapefroot/ds3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "second = pd.read_csv('sub_2.csv', index_col='test_id')\n",
    "\n",
    "first = pd.read_csv('sub_1.csv', index_col='test_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
